{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Multi-Label Text Classification for Stack Overflow Tag Prediction.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "We will implement a multilabel text classification algorithm for a tag suggestion system using Multi-Label Text Classification. more details about the business case can be found here: https://stackoverflow.blog/2019/05/06/predicting-stack-overflow-tags-with-googles-cloud-ai/"
      ],
      "metadata": {
        "id": "mhk64DG0J8IQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "62Cikf0c7i7O"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Load Dataset**\n",
        "\n",
        "Luckily such a dataset exists in BigQuery. This dataset includes a 26 GB table of Stack Overflow questions updated regularly "
      ],
      "metadata": {
        "id": "Rg9GubagB_yM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download the file using the `gsutil` CLI\n",
        "!gsutil cp 'gs://cloudml-demo-lcm/SO_ml_tags_avocado_188k_v2.csv' ./   "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hwdmCTRNYwh4",
        "outputId": "42752abf-1a7b-4f19-97cc-cd8a8d8776fc"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Copying gs://cloudml-demo-lcm/SO_ml_tags_avocado_188k_v2.csv...\n",
            "\\ [1 files][276.7 MiB/276.7 MiB]                                                \n",
            "Operation completed over 1 objects/276.7 MiB.                                    \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "KZmZKmZ7wFQV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Read, shuffle, and preview the data\n",
        "data = pd.read_csv('SO_ml_tags_avocado_188k_v2.csv', names=['tags', 'original_tags', 'text'], header=0)\n",
        "data = data.drop(columns=['original_tags'])\n",
        "data = data.dropna()\n",
        "data  = data.sample(frac=1) # shuffle\n",
        "data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "WQBti9SnY1iG",
        "outputId": "09bb16b0-fd4d-4a9b-81e6-216ed1ba4b81"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "              tags                                               text\n",
              "20023       pandas  how do i sum, average, count groupbys and stan...\n",
              "16850       pandas  reading and writing csv files into a data stru...\n",
              "49615       pandas  avocado dataframe o(1) index by column i have ...\n",
              "86255       pandas  avocado - unstack/pivot with multiple index i ...\n",
              "143421  tensorflow  what is the difference between the trainable_w..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-72b79a4d-7ed9-4164-bcc4-bdc650766438\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tags</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>20023</th>\n",
              "      <td>pandas</td>\n",
              "      <td>how do i sum, average, count groupbys and stan...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16850</th>\n",
              "      <td>pandas</td>\n",
              "      <td>reading and writing csv files into a data stru...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49615</th>\n",
              "      <td>pandas</td>\n",
              "      <td>avocado dataframe o(1) index by column i have ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>86255</th>\n",
              "      <td>pandas</td>\n",
              "      <td>avocado - unstack/pivot with multiple index i ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>143421</th>\n",
              "      <td>tensorflow</td>\n",
              "      <td>what is the difference between the trainable_w...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-72b79a4d-7ed9-4164-bcc4-bdc650766438')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-72b79a4d-7ed9-4164-bcc4-bdc650766438 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-72b79a4d-7ed9-4164-bcc4-bdc650766438');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data['text'][2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "id": "QhJhd0tZZooW",
        "outputId": "db1494c2-3788-46d0-f535-a03a7417457d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"non negative matrix factorisation in python on individual images i am trying to apply nmf to a particular image that is loaded in grayscale mode. i have tried several links but my image after application of nmf remains almost the same and cannot be distinguished with the grayscale image initially loaded.  however, when i come across the avocado-learn's code on implementing decomposition on a dataset, i see that the faces there have been transformed into ghost - like faces. here is the link:  http://avocado-learn.org/stable/auto_examples/decomposition/plot_faces_decomposition.html#sphx-glr-auto-examples-decomposition-plot-faces-decomposition-py  and here is the code i am using:  import cv2     from avocado import decomposition     import avocado.pyplot as avocado      img = cv2.imread('test1.jpeg',0)     estimator = decomposition.nmf(n_components = 2, init = 'nndsvda', tol = 5e-3)     estimator.fit(img)     vmax = max(img.max(), -img.min())     avocado.imshow(img, cmap=avocado.cm.gray, interpolation = 'nearest',vmin=-vmax,vmax=vmax)     avocado.show()   i am new to the techniques of nmf on matrices espicially such a large image numpy array. my image is test1.jpeg that is 225 * 224 .jpeg image.  can someone please help me on implementing the code for a single image? thanks a lot in advance.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qG3cYJvtZFs3",
        "outputId": "ce0d36dc-2a2e-455c-bce8-0f37f6bbc75d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(188199, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Split data\n"
      ],
      "metadata": {
        "id": "w3cMPd-aaMJ3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_size = int(len(data) * .8)\n",
        "\n",
        "train_data = data['text'].values[:train_size]\n",
        "test_data = data['text'].values[train_size:]"
      ],
      "metadata": {
        "id": "Ue-O0pHfaI-5"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " I create our Keras Tokenizer object. When we instantiate it we’ll need to choose a vocabulary size. Remember that this is the top N most frequent words our model will extract from our text data. "
      ],
      "metadata": {
        "id": "VGcl_-C6bi3o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing import text\n",
        "\n",
        "tokenizer = text.Tokenizer(num_words=400)\n",
        "tokenizer.fit_on_texts(train_data)\n",
        "\n",
        "train_data_toknized = tokenizer.texts_to_matrix(train_data)\n",
        "test_data_toknized = tokenizer.texts_to_matrix(test_data)"
      ],
      "metadata": {
        "id": "DxiwkbeIbS3P"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_toknized.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wD-R9uwFckCK",
        "outputId": "5b62b93a-c15e-46ce-af00-5f1f13070d91"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(150559, 400)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_toknized[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NzHX-3bsduio",
        "outputId": "ac6d2d15-cf24-4a9b-c08c-94c92acd5c17"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 0., 0., 0., 0.,\n",
              "       1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 1., 0., 0., 0., 1., 0., 0.,\n",
              "       0., 1., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 1., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 0., 0., 0., 0., 1.,\n",
              "       0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0.,\n",
              "       0., 1., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
              "       0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0.])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tags_split = [tags.split(',') for tags in data['tags'].values]\n",
        "tags_split[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4-rOiO08ZxWf",
        "outputId": "300502cc-adf0-46f1-cb7a-7f80c79882e4"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['pandas'], ['pandas'], ['pandas'], ['pandas'], ['tensorflow']]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Encoding Tags As Multi-Hot Arrays"
      ],
      "metadata": {
        "id": "-sHCH-FVbKwH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the encoder\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "\n",
        "tag_encoder = MultiLabelBinarizer()\n",
        "tags_encoded = tag_encoder.fit_transform(tags_split)\n",
        "\n",
        "# Split the tags into train/test\n",
        "train_labels = tags_encoded[:train_size]\n",
        "test_labels = tags_encoded[train_size:]"
      ],
      "metadata": {
        "id": "bnnKrtwvZpUf"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_labels[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RUEOTuCM9Bt7",
        "outputId": "da1153f6-9173-4354-e670-1fccaa76decf"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 0, 1, 0, 0],\n",
              "       [0, 0, 1, 0, 0],\n",
              "       [0, 0, 1, 0, 0],\n",
              "       [0, 0, 1, 0, 0],\n",
              "       [0, 0, 0, 0, 1]])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tag_encoder.classes_ "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tvEYPbUfHrJK",
        "outputId": "8937254b-98ef-4ea9-e925-2381143571ca"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['keras', 'matplotlib', 'pandas', 'scikitlearn', 'tensorflow'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Model 0: Baseline Model using Naive Bayes**\n",
        "\n",
        "The Multi-label algorithm accepts a binary mask over multiple labels. The result for each prediction will be an array of 0s and 1s marking which class labels apply to each row input sample.\n",
        "\n",
        "OneVsRest strategy can be used for multi-label learning, where a classifier is used to predict multiple labels for instance. Naive Bayes supports multi-class, but we are in a multi-label scenario, therefore, we wrap Naive Bayes in the OneVsRestClassifier.\n"
      ],
      "metadata": {
        "id": "270iWOoya3Xd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "\n",
        "\n",
        "model_0 = Pipeline([\n",
        "                    ('tfidf',TfidfVectorizer()),\n",
        "                    ('MNB', OneVsRestClassifier(MultinomialNB()))\n",
        "])\n",
        "\n",
        "model_0.fit(train_data, train_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EVcRS1ahao7J",
        "outputId": "a2211f0c-f544-45c1-ef22-1f58427fcf64"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('tfidf', TfidfVectorizer()),\n",
              "                ('MNB', OneVsRestClassifier(estimator=MultinomialNB()))])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_0.score(test_data, test_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aeirRH9BdoN0",
        "outputId": "96a5d423-6ca3-489e-f542-14c5399adf6f"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6224495217853347"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "8Ip0GIzIwnUU"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score\n",
        "pred_0 = model_0.predict(test_data)\n",
        "f1_score(pred_0,test_labels, average='micro' )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oAFh5b4QepmE",
        "outputId": "5fb17039-70cd-45dc-c577-b6f043abaec7"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7458886587891339"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "uQfViK4hS37I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "9o1Cgoa2S7n-"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Model 1: Fully Connected Neural Network**\n",
        "\n",
        " I have used sigmoid function as it will convert each of our 5 outputs to a value between 0 and 1 indicating the probability that a specific label corresponds with that input. Here’s an example output for a question tagged ‘keras’ and ‘tensorflow’:\n",
        "\n",
        "[ .89   .02   .001   .21   .96  ]\n",
        "Notice that because a question can have multiple tags in this model, the sigmoid output does not add up to 1. If a question could only have exactly one tag, we’d use the Softmax activation function instead and the 5-element output array would add up to 1. We can now train and evaluate our model:"
      ],
      "metadata": {
        "id": "5cgh6vEHbAHD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "model_1 = tf.keras.models.Sequential()\n",
        "\n",
        "\n",
        "model_1.add(tf.keras.layers.Dense(50, input_shape=(400,), activation='relu'))\n",
        "model_1.add(tf.keras.layers.Dense(25, activation='relu'))\n",
        "model_1.add(tf.keras.layers.Dense(5, activation='sigmoid'))\n",
        "\n",
        "model_1.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "rIY8LoIEbA6X"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_1.fit(train_data_toknized, train_labels, epochs=5, batch_size=32, validation_data=[test_data_toknized, test_labels])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "czlSzJWrcCcP",
        "outputId": "2bdd042d-0f31-4333-fa37-f679e87c792a"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "4705/4705 [==============================] - 16s 3ms/step - loss: 0.1209 - accuracy: 0.8788 - val_loss: 0.1030 - val_accuracy: 0.8922\n",
            "Epoch 2/5\n",
            "4705/4705 [==============================] - 14s 3ms/step - loss: 0.0996 - accuracy: 0.8964 - val_loss: 0.0989 - val_accuracy: 0.8992\n",
            "Epoch 3/5\n",
            "4705/4705 [==============================] - 15s 3ms/step - loss: 0.0945 - accuracy: 0.9007 - val_loss: 0.0978 - val_accuracy: 0.9032\n",
            "Epoch 4/5\n",
            "4705/4705 [==============================] - 20s 4ms/step - loss: 0.0908 - accuracy: 0.9048 - val_loss: 0.0984 - val_accuracy: 0.9004\n",
            "Epoch 5/5\n",
            "4705/4705 [==============================] - 17s 4ms/step - loss: 0.0878 - accuracy: 0.9079 - val_loss: 0.0984 - val_accuracy: 0.9039\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fcf611419d0>"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_1.evaluate(test_data_toknized, test_labels, batch_size=128)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P0alvgHscTD9",
        "outputId": "17427c5e-3e25-453f-b64a-3ae0053b6f4e"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "295/295 [==============================] - 1s 2ms/step - loss: 0.0984 - accuracy: 0.9039\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.09838633239269257, 0.9039053916931152]"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "R29kcupwZY1F"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred_1 = model_1.predict(test_data_toknized)\n",
        "pred_1 =  np.round(pred_1)\n",
        "pred_1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pUJUGpMMdkX_",
        "outputId": "cffd33b3-158e-4e06-e556-327e24a0c78b"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 1., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0.],\n",
              "       [0., 0., 1., 0., 0.],\n",
              "       ...,\n",
              "       [0., 1., 1., 0., 0.],\n",
              "       [0., 1., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "f1_score(pred_1,test_labels , average= 'micro')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6zcG8Btbjn9y",
        "outputId": "4b53d2e3-ba7b-4250-f67d-fb699cc20482"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9081044250690824"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred_1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "boNsjztsZat3",
        "outputId": "56ce4687-e7e7-4a22-e537-b2d44ce9b6e5"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 1., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0.],\n",
              "       [0., 0., 1., 0., 0.],\n",
              "       ...,\n",
              "       [0., 1., 1., 0., 0.],\n",
              "       [0., 1., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Model 2: Embedding layer + Conv1D Layer**"
      ],
      "metadata": {
        "id": "RsfK8hwOhvse"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create text vectorizer layer\n",
        "max_token = 5000\n",
        "output_seq_len = 55\n",
        "embedding_dims = 128\n",
        "text_victorizer = tf.keras.layers.TextVectorization(\n",
        "    max_tokens=max_token, standardize='lower_and_strip_punctuation',\n",
        "    split='whitespace', ngrams=None, output_mode='int',\n",
        "    output_sequence_length=output_seq_len)"
      ],
      "metadata": {
        "id": "rersAWDihar1"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_victorizer.adapt(train_data)"
      ],
      "metadata": {
        "id": "373IAvrKxKEx"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "token_embed = tf.keras.layers.Embedding(input_dim = 5000 ,\n",
        "                               \n",
        "                               output_dim = 128,\n",
        "                               mask_zero= True\n",
        "                               )"
      ],
      "metadata": {
        "id": "yzduSnRkxv67"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a model using Conv ID to process the text data and predict the target\n",
        "\n",
        "\n",
        "inputs = tf.keras.Input(shape=(1,), dtype=tf.string, name='text')\n",
        "\n",
        "X = text_victorizer(inputs)\n",
        "X = token_embed(X)\n",
        "\n",
        "\n",
        "X = tf.keras.layers.Conv1D(64,5, activation='relu', padding = 'same')(X)\n",
        "X = tf.keras.layers.Conv1D(64,5, activation='relu', padding = 'same')(X)\n",
        "X = tf.keras.layers.GlobalAveragePooling1D()(X)\n",
        "\n",
        "output = tf.keras.layers.Dense(5, activation= 'sigmoid') (X)\n",
        "model_2 = tf.keras.Model(inputs, output)"
      ],
      "metadata": {
        "id": "lwkTWEhwxP2F"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import metrics\n",
        "model_2.compile(optimizer = tf.keras.optimizers.Adam(),\n",
        "                loss = 'binary_crossentropy',\n",
        "                metrics = ['accuracy'])"
      ],
      "metadata": {
        "id": "UBwukjkVx9JV"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_2.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ob5OEQxeyGeE",
        "outputId": "5e34be30-109a-43f5-c186-562d2f14949f"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " text (InputLayer)           [(None, 1)]               0         \n",
            "                                                                 \n",
            " text_vectorization (TextVec  (None, 55)               0         \n",
            " torization)                                                     \n",
            "                                                                 \n",
            " embedding (Embedding)       (None, 55, 128)           640000    \n",
            "                                                                 \n",
            " conv1d (Conv1D)             (None, 55, 64)            41024     \n",
            "                                                                 \n",
            " conv1d_1 (Conv1D)           (None, 55, 64)            20544     \n",
            "                                                                 \n",
            " global_average_pooling1d (G  (None, 64)               0         \n",
            " lobalAveragePooling1D)                                          \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 5)                 325       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 701,893\n",
            "Trainable params: 701,893\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_2.fit(train_data, train_labels, epochs=8, batch_size=32, validation_data=[test_data, test_labels])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q17mYqTyyOL2",
        "outputId": "4a28f451-007b-4f28-fb5d-b077995416f0"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/8\n",
            "4705/4705 [==============================] - 47s 8ms/step - loss: 0.1435 - accuracy: 0.8579 - val_loss: 0.1201 - val_accuracy: 0.8824\n",
            "Epoch 2/8\n",
            "4705/4705 [==============================] - 40s 8ms/step - loss: 0.1131 - accuracy: 0.8921 - val_loss: 0.1148 - val_accuracy: 0.8912\n",
            "Epoch 3/8\n",
            "4705/4705 [==============================] - 39s 8ms/step - loss: 0.1045 - accuracy: 0.8991 - val_loss: 0.1149 - val_accuracy: 0.8954\n",
            "Epoch 4/8\n",
            "4705/4705 [==============================] - 39s 8ms/step - loss: 0.0971 - accuracy: 0.9061 - val_loss: 0.1136 - val_accuracy: 0.8896\n",
            "Epoch 5/8\n",
            "4705/4705 [==============================] - 40s 8ms/step - loss: 0.0896 - accuracy: 0.9118 - val_loss: 0.1157 - val_accuracy: 0.8871\n",
            "Epoch 6/8\n",
            "4705/4705 [==============================] - 40s 8ms/step - loss: 0.0815 - accuracy: 0.9194 - val_loss: 0.1215 - val_accuracy: 0.8921\n",
            "Epoch 7/8\n",
            "4705/4705 [==============================] - 40s 8ms/step - loss: 0.0724 - accuracy: 0.9270 - val_loss: 0.1302 - val_accuracy: 0.8843\n",
            "Epoch 8/8\n",
            "4705/4705 [==============================] - 40s 8ms/step - loss: 0.0627 - accuracy: 0.9352 - val_loss: 0.1422 - val_accuracy: 0.8836\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fcf5c186dd0>"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred_2 = model_2.predict(test_data)\n",
        "pred_2 =  np.round(pred_2)\n",
        "\n",
        "f1_score(pred_2,test_labels , average= 'micro')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SXA32RFs0yMX",
        "outputId": "25208407-7610-4970-b606-23ed67fd3f82"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8868466254591959"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Create Data pipline**"
      ],
      "metadata": {
        "id": "IGdoqfPhVWUt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "train_data  = tf.data.Dataset.from_tensor_slices((train_data, train_labels))\n",
        "test_data = tf.data.Dataset.from_tensor_slices((test_data, test_labels))\n",
        "\n",
        "train_data = train_data.batch(32).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "test_data = test_data.batch(32).prefetch(tf.data.AUTOTUNE)"
      ],
      "metadata": {
        "id": "WA39DGt1VN6q"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Model 3: Feature Extraction with pretrained tokens (Transfer learning using universal sentence encoder)**"
      ],
      "metadata": {
        "id": "-bOQPE3eys3u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow_hub as hub\n",
        "layer_url = \"https://tfhub.dev/google/universal-sentence-encoder/4\"\n",
        "USE_layer = hub.KerasLayer(layer_url, trainable=False)\n",
        "\n",
        "inputs = tf.keras.Input(shape=[], dtype=tf.string, name='text')\n",
        "\n",
        "#Use USE layer without needing to tonkize as it is handled with the layer. The layer encode each sentence into vector of 512\n",
        "X = USE_layer(inputs)\n",
        "\n",
        "\n",
        "X = tf.keras.layers.Dense(128, activation='relu')(X)\n",
        "\n",
        "output = tf.keras.layers.Dense(5, activation= 'sigmoid') (X)\n",
        "model_3 = tf.keras.Model(inputs, output)"
      ],
      "metadata": {
        "id": "avv49ddN1Svf"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import metrics\n",
        "model_3.compile(optimizer = tf.keras.optimizers.Adam(),\n",
        "                loss = 'binary_crossentropy',\n",
        "                metrics = ['accuracy'])"
      ],
      "metadata": {
        "id": "TX0lTIq_1dOU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_3.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "njgGNNUF1m6Q",
        "outputId": "70301608-363d-4d70-f078-aac5821a976a"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " text (InputLayer)           [(None,)]                 0         \n",
            "                                                                 \n",
            " keras_layer (KerasLayer)    (None, 512)               256797824 \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 128)               65664     \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 5)                 645       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 256,864,133\n",
            "Trainable params: 66,309\n",
            "Non-trainable params: 256,797,824\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_3.fit(train_data, epochs=8, steps_per_epoch = int(0.1*len(train_data)),\n",
        "      validation_data= test_data, validation_steps = int(0.1*len(test_data)) )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mrOyVlec1i4q",
        "outputId": "261c3a03-f0c4-4ab6-a124-aed8076c4abc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/8\n",
            "470/470 [==============================] - 22s 43ms/step - loss: 0.2389 - accuracy: 0.7517 - val_loss: 0.1713 - val_accuracy: 0.8189\n",
            "Epoch 2/8\n",
            "470/470 [==============================] - 20s 43ms/step - loss: 0.1668 - accuracy: 0.8186 - val_loss: 0.1578 - val_accuracy: 0.8293\n",
            "Epoch 3/8\n",
            "470/470 [==============================] - 20s 42ms/step - loss: 0.1595 - accuracy: 0.8285 - val_loss: 0.1501 - val_accuracy: 0.8379\n",
            "Epoch 4/8\n",
            "470/470 [==============================] - 20s 42ms/step - loss: 0.1527 - accuracy: 0.8400 - val_loss: 0.1481 - val_accuracy: 0.8413\n",
            "Epoch 5/8\n",
            "470/470 [==============================] - 20s 42ms/step - loss: 0.1497 - accuracy: 0.8419 - val_loss: 0.1482 - val_accuracy: 0.8424\n",
            "Epoch 6/8\n",
            "470/470 [==============================] - 19s 41ms/step - loss: 0.1497 - accuracy: 0.8400 - val_loss: 0.1445 - val_accuracy: 0.8456\n",
            "Epoch 7/8\n",
            "470/470 [==============================] - 20s 42ms/step - loss: 0.1498 - accuracy: 0.8431 - val_loss: 0.1430 - val_accuracy: 0.8451\n",
            "Epoch 8/8\n",
            "172/470 [=========>....................] - ETA: 9s - loss: 0.1499 - accuracy: 0.8403"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred_3 = model_3.predict(test_data)\n",
        "pred_3=  np.round(pred_3)\n",
        "\n",
        "f1_score(pred_3,test_labels , average= 'micro')"
      ],
      "metadata": {
        "id": "zyCavGyuoH0o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "o8QTP9Yj1xVQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Model 4: Feature Extraction with pretrained tokens (Transfer learning using BERT or ELMO)**\n",
        "\n",
        "More information about BERT emebdding can be found here https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/. Another example that shows how to use it can be found here: https://towardsdatascience.com/simple-bert-using-tensorflow-2-0-132cb19e9b22 . The encoder's outputs are the 'pooled_output' to represents each input sequence as a whole, and the 'sequence_output' to represent each input token in context. Either of those can be used as input to further model building. Read this https://www.tensorflow.org/text/tutorials/classify_text_with_bert"
      ],
      "metadata": {
        "id": "DejH2shq8gJO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "rSsnNECvXq7W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow_text\n",
        "import tensorflow_text"
      ],
      "metadata": {
        "id": "I_NKOuu9j2oe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = tf.keras.Input(shape=(), dtype=tf.string, name='text')\n",
        "\n",
        "#Use USE layer without needing to tonkize as it is handled with the layer. The layer encode each sentence into vector of 512\n",
        "preprocessor = hub.KerasLayer(\n",
        "    \"https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3\")\n",
        "encoder_inputs = preprocessor(inputs) # dict with keys: 'input_mask', 'input_type_ids', 'input_word_ids'\n",
        "encoder = hub.KerasLayer(\n",
        "    \"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/4\",\n",
        "    trainable=False)\n",
        "outputs  = encoder(encoder_inputs)\n",
        "X =  outputs['pooled_output']\n",
        "X = tf.keras.layers.Dense(128, activation='relu')(X)\n",
        "\n",
        "output = tf.keras.layers.Dense(5, activation= 'sigmoid')(X)\n",
        "model_4 = tf.keras.Model(inputs, output)"
      ],
      "metadata": {
        "id": "I9BDF9TEVjzP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model_4.compile(optimizer = tf.keras.optimizers.Adam(),\n",
        "                loss = 'binary_crossentropy',\n",
        "                metrics = ['accuracy'])\n",
        "model_4.summary()"
      ],
      "metadata": {
        "id": "6VeFJn9sWIbW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_4.fit(train_data, epochs=8, steps_per_epoch = int(0.1*len(train_data)),\n",
        "      validation_data= test_data, validation_steps = int(0.1*len(test_data)) )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "URksiFmB9RI_",
        "outputId": "7c3b9a95-01f3-4d13-881a-5e0d512111c3"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/8\n",
            "470/470 [==============================] - 148s 299ms/step - loss: 0.3969 - accuracy: 0.5453 - val_loss: 0.4143 - val_accuracy: 0.5216\n",
            "Epoch 2/8\n",
            "470/470 [==============================] - 139s 297ms/step - loss: 0.3323 - accuracy: 0.6309 - val_loss: 0.3052 - val_accuracy: 0.6514\n",
            "Epoch 3/8\n",
            "470/470 [==============================] - 140s 299ms/step - loss: 0.3094 - accuracy: 0.6612 - val_loss: 0.2880 - val_accuracy: 0.6752\n",
            "Epoch 4/8\n",
            "470/470 [==============================] - 140s 298ms/step - loss: 0.2929 - accuracy: 0.6840 - val_loss: 0.2788 - val_accuracy: 0.6864\n",
            "Epoch 5/8\n",
            "470/470 [==============================] - 140s 297ms/step - loss: 0.2790 - accuracy: 0.6989 - val_loss: 0.2951 - val_accuracy: 0.6782\n",
            "Epoch 6/8\n",
            "470/470 [==============================] - 139s 297ms/step - loss: 0.2787 - accuracy: 0.6911 - val_loss: 0.2723 - val_accuracy: 0.7147\n",
            "Epoch 7/8\n",
            "470/470 [==============================] - 140s 297ms/step - loss: 0.2751 - accuracy: 0.6965 - val_loss: 0.2603 - val_accuracy: 0.7225\n",
            "Epoch 8/8\n",
            "470/470 [==============================] - 141s 299ms/step - loss: 0.2663 - accuracy: 0.7117 - val_loss: 0.2688 - val_accuracy: 0.7131\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fcf5aac0590>"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred_4 = model_4.predict(test_data)\n",
        "pred_4=  np.round(pred_4)\n",
        "\n",
        "f1_score(pred_4,test_labels , average= 'micro')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uTRqrI5D9Xq6",
        "outputId": "bc9462e3-dc7c-437f-d047-e97ed977353f"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7076116229624381"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Model 5: Feature Extraction with pretrained tokens (Transfer learning using universal sentence encoder) + LSTM layer**"
      ],
      "metadata": {
        "id": "LVKM18q7AAbI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow_hub as hub\n",
        "layer_url = \"https://tfhub.dev/google/universal-sentence-encoder/4\"\n",
        "USE_layer = hub.KerasLayer(layer_url, trainable=False)\n",
        "\n",
        "inputs = tf.keras.Input(shape=[], dtype=tf.string, name='text')\n",
        "\n",
        "#Use USE layer without needing to tonkize as it is handled with the layer. The layer encode each sentence into vector of 512\n",
        "X = USE_layer(inputs)\n",
        "\n",
        "\n",
        "X = tf.reshape(X, [-1,512, 1])\n",
        "X = tf.keras.layers.LSTM(64, activation='tanh')(X)\n",
        "X = tf.keras.layers.Dense(64, activation='relu')(X)\n",
        "\n",
        "output = tf.keras.layers.Dense(5, activation= 'sigmoid') (X)\n",
        "model_5 = tf.keras.Model(inputs, output)"
      ],
      "metadata": {
        "id": "q6fElYVBAByG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_5.compile(optimizer = tf.keras.optimizers.Adam(),\n",
        "                loss = 'binary_crossentropy',\n",
        "                metrics = ['accuracy'])\n",
        "model_5.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Suw4z31VAqsH",
        "outputId": "f74fb6b9-b9c2-41a7-c980-3ed738a122c5"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " text (InputLayer)           [(None,)]                 0         \n",
            "                                                                 \n",
            " keras_layer_3 (KerasLayer)  (None, 512)               256797824 \n",
            "                                                                 \n",
            " tf.reshape (TFOpLambda)     (None, 512, 1)            0         \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 64)                16896     \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 64)                4160      \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 5)                 325       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 256,819,205\n",
            "Trainable params: 21,381\n",
            "Non-trainable params: 256,797,824\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " model_5.fit(train_data, epochs=8, steps_per_epoch = int(len(train_data)/32),\n",
        "      validation_data= test_data, validation_steps = int(len(test_data)/32) )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EpqAWiJkA3Vx",
        "outputId": "876ba287-d372-4fcd-dcf5-13e0e99917ae"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/8\n",
            "147/147 [==============================] - 15s 74ms/step - loss: 0.4707 - accuracy: 0.4630 - val_loss: 0.4385 - val_accuracy: 0.5061\n",
            "Epoch 2/8\n",
            "147/147 [==============================] - 10s 70ms/step - loss: 0.4458 - accuracy: 0.4896 - val_loss: 0.4391 - val_accuracy: 0.5061\n",
            "Epoch 3/8\n",
            "147/147 [==============================] - 10s 68ms/step - loss: 0.4494 - accuracy: 0.4892 - val_loss: 0.4382 - val_accuracy: 0.5061\n",
            "Epoch 4/8\n",
            "147/147 [==============================] - 10s 70ms/step - loss: 0.4450 - accuracy: 0.4985 - val_loss: 0.4394 - val_accuracy: 0.5061\n",
            "Epoch 5/8\n",
            "147/147 [==============================] - 10s 68ms/step - loss: 0.4463 - accuracy: 0.4860 - val_loss: 0.4391 - val_accuracy: 0.5061\n",
            "Epoch 6/8\n",
            "147/147 [==============================] - 10s 66ms/step - loss: 0.4468 - accuracy: 0.4917 - val_loss: 0.4389 - val_accuracy: 0.5061\n",
            "Epoch 7/8\n",
            "147/147 [==============================] - 10s 66ms/step - loss: 0.4460 - accuracy: 0.4881 - val_loss: 0.4383 - val_accuracy: 0.5061\n",
            "Epoch 8/8\n",
            "147/147 [==============================] - 10s 66ms/step - loss: 0.4453 - accuracy: 0.4983 - val_loss: 0.4381 - val_accuracy: 0.5061\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fcdc2440850>"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred_5 = model_5.predict(test_data)\n",
        "pred_5=  np.round(pred_5)\n",
        "\n",
        "f1_score(pred_5,test_labels , average= 'micro')"
      ],
      "metadata": {
        "id": "h6KBtC99A5sW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Model 6: Embeddding Layer + 2 LSTM Layer**"
      ],
      "metadata": {
        "id": "4vt2vA6MBlnM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "inputs = tf.keras.Input(shape=(1,), dtype=tf.string, name='text')\n",
        "\n",
        "X = text_victorizer(inputs)\n",
        "X = token_embed(X)\n",
        "\n",
        "\n",
        "X = tf.keras.layers.LSTM(128, activation='tanh', return_sequences=True)(X)\n",
        "X = tf.keras.layers.LSTM(128, activation='tanh')(X)\n",
        "X = tf.keras.layers.Dense(128, activation='relu')(X)\n",
        "\n",
        "output = tf.keras.layers.Dense(5, activation= 'sigmoid')(X)\n",
        "model_6 = tf.keras.Model(inputs, output)"
      ],
      "metadata": {
        "id": "4jhMlErYBuHc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_6.compile(optimizer = tf.keras.optimizers.Adam(),\n",
        "                loss = 'binary_crossentropy',\n",
        "                metrics = ['accuracy'])\n",
        "model_5.summary()"
      ],
      "metadata": {
        "id": "0r0NenbiB438"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_6.fit(train_data, epochs=8, steps_per_epoch = int(len(train_data)/32),\n",
        "      validation_data= test_data, validation_steps = int(len(test_data)/32) )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Krf1dI4XB8t9",
        "outputId": "e9981501-12f3-47ee-f24d-ce4c732d12c6"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/8\n",
            "147/147 [==============================] - 11s 34ms/step - loss: 0.2627 - accuracy: 0.7307 - val_loss: 0.1864 - val_accuracy: 0.8177\n",
            "Epoch 2/8\n",
            "147/147 [==============================] - 3s 19ms/step - loss: 0.1751 - accuracy: 0.8221 - val_loss: 0.1610 - val_accuracy: 0.8472\n",
            "Epoch 3/8\n",
            "147/147 [==============================] - 3s 19ms/step - loss: 0.1684 - accuracy: 0.8261 - val_loss: 0.1542 - val_accuracy: 0.8533\n",
            "Epoch 4/8\n",
            "147/147 [==============================] - 3s 19ms/step - loss: 0.1618 - accuracy: 0.8397 - val_loss: 0.1454 - val_accuracy: 0.8594\n",
            "Epoch 5/8\n",
            "147/147 [==============================] - 3s 19ms/step - loss: 0.1456 - accuracy: 0.8484 - val_loss: 0.1319 - val_accuracy: 0.8733\n",
            "Epoch 6/8\n",
            "147/147 [==============================] - 3s 19ms/step - loss: 0.1251 - accuracy: 0.8741 - val_loss: 0.1335 - val_accuracy: 0.8776\n",
            "Epoch 7/8\n",
            "147/147 [==============================] - 3s 19ms/step - loss: 0.1207 - accuracy: 0.8835 - val_loss: 0.1196 - val_accuracy: 0.8941\n",
            "Epoch 8/8\n",
            "147/147 [==============================] - 3s 19ms/step - loss: 0.1192 - accuracy: 0.8897 - val_loss: 0.1194 - val_accuracy: 0.8898\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fcdc0516290>"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred_6 = model_6.predict(test_data)\n",
        "pred_6=  np.round(pred_6)\n",
        "\n",
        "f1_score(pred_6,test_labels , average= 'micro')"
      ],
      "metadata": {
        "id": "cCyPipnyB_m8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}